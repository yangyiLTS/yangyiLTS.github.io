<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="爬虫,Python," />










<meta name="description" content="翻译自开源书籍500 Lines or Less中A Web Crawler With asyncio Coroutines一节。 A Web Crawler With asyncio Coroutines - A. Jesse Jiryu Davis and Guido van Rossum 第一部分见翻译 | 500 Lines or Less 基于Python协程的网页爬虫 （一）">
<meta name="keywords" content="爬虫,Python">
<meta property="og:type" content="article">
<meta property="og:title" content="翻译 | 500 Lines or Less 基于Python协程的网页爬虫 （二）">
<meta property="og:url" content="https://www.yangyilts.com/2018/A-Web-Crawler-With-asyncio-Coroutines-Part-2.html/index.html">
<meta property="og:site_name" content="洋溢着温暖的微笑">
<meta property="og:description" content="翻译自开源书籍500 Lines or Less中A Web Crawler With asyncio Coroutines一节。 A Web Crawler With asyncio Coroutines - A. Jesse Jiryu Davis and Guido van Rossum 第一部分见翻译 | 500 Lines or Less 基于Python协程的网页爬虫 （一）">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://picbucket-1253466787.image.myqcloud.com/2018.2/Yield_From.png">
<meta property="og:image" content="https://picbucket-1253466787.image.myqcloud.com/2018.2/redirects.png">
<meta property="og:updated_time" content="2018-03-04T13:49:03.250Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="翻译 | 500 Lines or Less 基于Python协程的网页爬虫 （二）">
<meta name="twitter:description" content="翻译自开源书籍500 Lines or Less中A Web Crawler With asyncio Coroutines一节。 A Web Crawler With asyncio Coroutines - A. Jesse Jiryu Davis and Guido van Rossum 第一部分见翻译 | 500 Lines or Less 基于Python协程的网页爬虫 （一）">
<meta name="twitter:image" content="https://picbucket-1253466787.image.myqcloud.com/2018.2/Yield_From.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://www.yangyilts.com/2018/A-Web-Crawler-With-asyncio-Coroutines-Part-2.html/"/>





  <title>翻译 | 500 Lines or Less 基于Python协程的网页爬虫 （二） | 洋溢着温暖的微笑</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">洋溢着温暖的微笑</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.yangyilts.com/2018/A-Web-Crawler-With-asyncio-Coroutines-Part-2.html/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="YANG Yi">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/sheep.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="洋溢着温暖的微笑">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">翻译 | 500 Lines or Less 基于Python协程的网页爬虫 （二）</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-02-13T16:54:30+08:00">
                2018-02-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/technology/" itemprop="url" rel="index">
                    <span itemprop="name">技术宅</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/A-Web-Crawler-With-asyncio-Coroutines-Part-2.html/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/A-Web-Crawler-With-asyncio-Coroutines-Part-2.html/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  6,563
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>翻译自开源书籍500 Lines or Less中A Web Crawler With asyncio Coroutines一节。</p>
<p><a href="http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html" target="_blank" rel="noopener">A Web Crawler With asyncio Coroutines - A. Jesse Jiryu Davis and Guido van Rossum</a></p>
<p>第一部分见<br><a href="https://www.yangyilts.com/2018/A-Web-Crawler-With-asyncio-Coroutines-Part-1.html/">翻译 | 500 Lines or Less 基于Python协程的网页爬虫 （一）</a></p>
<a id="more"></a>
<h1 id="用生成器构建协程"><a href="#用生成器构建协程" class="headerlink" title="用生成器构建协程"></a>用生成器构建协程</h1><p><strong>Building Coroutines With Generators</strong></p>
<p>所以一个生成器可以暂停，可以用一个值恢复，并且它有一个返回值。听起来是一个很好的特性，可以在不使用面条式的回调函数的情况下编写一个异步I/O模块。我们的目的是构建一个“协程”：一个可以在程序中与其它例程合作调度的例程。我们的协程是Python标准库”asynico”中协程的一个简化版本。就像在asyncio库中一样，我们会使用生成器，futures类，和”yield from”语句。</p>
<p>首先，我们需要一个方法来表示一个协程正在等待的future类事件，一个简化版本为：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Future</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.result = <span class="keyword">None</span></span><br><span class="line">        self._callbacks = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_done_callback</span><span class="params">(self, fn)</span>:</span></span><br><span class="line">        self._callbacks.append(fn)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_result</span><span class="params">(self, result)</span>:</span></span><br><span class="line">        self.result = result</span><br><span class="line">        <span class="keyword">for</span> fn <span class="keyword">in</span> self._callbacks:</span><br><span class="line">            fn(self)</span><br></pre></td></tr></table></figure>
<p>一个future被初始化为“未解决的”，他通过调用<code>set_result</code>来解决。</p>
<p>让我们用futures类和协程来改写我们的抓取器。先使用回调函数编写一个fetch：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Fetcher</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fetch</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.sock = socket.socket()</span><br><span class="line">        self.sock.setblocking(<span class="keyword">False</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.sock.connect((<span class="string">'xkcd.com'</span>, <span class="number">80</span>))</span><br><span class="line">        <span class="keyword">except</span> BlockingIOError:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        selector.register(self.sock.fileno(),</span><br><span class="line">                          EVENT_WRITE,</span><br><span class="line">                          self.connected)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">connected</span><span class="params">(self, key, mask)</span>:</span></span><br><span class="line">        print(<span class="string">'connected!'</span>)</span><br><span class="line">        <span class="comment"># And so on....</span></span><br></pre></td></tr></table></figure>
<p><code>fetch</code>方法从连接一个socket开始，然后注册一个回调函数<code>connected</code>，当socket准备好的时候执行<code>connected</code>。现在，我们可以把两个步骤整合在一个协程里面：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fetch</span><span class="params">(self)</span>:</span></span><br><span class="line">    sock = socket.socket()</span><br><span class="line">    sock.setblocking(<span class="keyword">False</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        sock.connect((<span class="string">'xkcd.com'</span>, <span class="number">80</span>))</span><br><span class="line">    <span class="keyword">except</span> BlockingIOError:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    f = Future()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_connected</span><span class="params">()</span>:</span></span><br><span class="line">        f.set_result(<span class="keyword">None</span>)</span><br><span class="line"></span><br><span class="line">    selector.register(sock.fileno(),</span><br><span class="line">                      EVENT_WRITE,</span><br><span class="line">                      on_connected)</span><br><span class="line">    <span class="keyword">yield</span> f</span><br><span class="line">    selector.unregister(sock.fileno())</span><br><span class="line">    print(<span class="string">'connected!'</span>)</span><br></pre></td></tr></table></figure>
<p>现在<code>fetch</code>已经是一个生成器函数，相比于普通的函数，它包含了一个<code>yield</code>语句。我们创建一个未定的future，然后yield它，它会暂停直到socket连接建立。内建函数<code>on_connected</code>解决了这个future。</p>
<p>但是当future解决的时候，谁来回复这个生成器？我们需要一个协程<em>驱动</em>。把它称为”task”：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Task</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, coro)</span>:</span></span><br><span class="line">        self.coro = coro</span><br><span class="line">        f = Future()</span><br><span class="line">        f.set_result(<span class="keyword">None</span>)</span><br><span class="line">        self.step(f)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">step</span><span class="params">(self, future)</span>:</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            next_future = self.coro.send(future.result)</span><br><span class="line">        <span class="keyword">except</span> StopIteration:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        next_future.add_done_callback(self.step)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Begin fetching http://xkcd.com/353/</span></span><br><span class="line">fetcher = Fetcher(<span class="string">'/353/'</span>)</span><br><span class="line">Task(fetcher.fetch())</span><br><span class="line">loop()</span><br></pre></td></tr></table></figure>
<p>task向<code>fetch</code>生成器发送<code>None</code>来启动它。<code>fetch</code>运行到它yield出一个future，task捕获它命名为<code>next_future</code>。当socket建立的时候，事件循环启动<code>on_connected</code>回调函数，它会解决future，调用<code>step</code>，恢复<code>fetch</code>。</p>
<h1 id="用yield-from重构协程"><a href="#用yield-from重构协程" class="headerlink" title="用yield from重构协程"></a>用<code>yield from</code>重构协程</h1><p><strong>Factoring Coroutines With <code>yield from</code></strong></p>
<p>一旦socket的连接建立，我们向服务器发送一个HTTP GET请求，然后读取服务器的响应。这些步骤不需要分散在回调函数中；我们把它整合在同一个生成器函数里面：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fetch</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="comment"># ... connection logic from above, then:</span></span><br><span class="line">    sock.send(request.encode(<span class="string">'ascii'</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        f = Future()</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">on_readable</span><span class="params">()</span>:</span></span><br><span class="line">            f.set_result(sock.recv(<span class="number">4096</span>))</span><br><span class="line"></span><br><span class="line">        selector.register(sock.fileno(),</span><br><span class="line">                          EVENT_READ,</span><br><span class="line">                          on_readable)</span><br><span class="line">        chunk = <span class="keyword">yield</span> f</span><br><span class="line">        selector.unregister(sock.fileno())</span><br><span class="line">        <span class="keyword">if</span> chunk:</span><br><span class="line">            self.response += chunk</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># Done reading.</span></span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>这种从socket读取全部消息的代码看起来是可以起作用的。那么我们如何把它分解为一个字程序呢？现在Python著名的<code>yield from</code>语句登场了。它将一个生成器委派给另一个生成器，</p>
<p>为了看清楚原理，我们回到我们那个简单的生成器例子：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">gen_fn</span><span class="params">()</span>:</span></span><br><span class="line"><span class="meta">... </span>    result = <span class="keyword">yield</span> <span class="number">1</span></span><br><span class="line"><span class="meta">... </span>    print(<span class="string">'result of yield: &#123;&#125;'</span>.format(result))</span><br><span class="line"><span class="meta">... </span>    result2 = <span class="keyword">yield</span> <span class="number">2</span></span><br><span class="line"><span class="meta">... </span>    print(<span class="string">'result of 2nd yield: &#123;&#125;'</span>.format(result2))</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> <span class="string">'done'</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>为了在另一个生成器中调用这个生成器，用<code>yield from</code>委派它：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Generator function:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">caller_fn</span><span class="params">()</span>:</span></span><br><span class="line"><span class="meta">... </span>    gen = gen_fn()</span><br><span class="line"><span class="meta">... </span>    rv = <span class="keyword">yield</span> <span class="keyword">from</span> gen</span><br><span class="line"><span class="meta">... </span>    print(<span class="string">'return value of yield-from: &#123;&#125;'</span></span><br><span class="line"><span class="meta">... </span>          .format(rv))</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Make a generator from the</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># generator function.</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>caller = caller_fn()</span><br></pre></td></tr></table></figure>
<p><code>caller</code>生成器的行为就好像是<code>gen</code>一样，这个生成器被委派给：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>caller.send(<span class="keyword">None</span>)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>caller.gi_frame.f_lasti</span><br><span class="line"><span class="number">15</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>caller.send(<span class="string">'hello'</span>)</span><br><span class="line">result of <span class="keyword">yield</span>: hello</span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>caller.gi_frame.f_lasti  <span class="comment"># Hasn't advanced.</span></span><br><span class="line"><span class="number">15</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>caller.send(<span class="string">'goodbye'</span>)</span><br><span class="line">result of <span class="number">2</span>nd <span class="keyword">yield</span>: goodbye</span><br><span class="line"><span class="keyword">return</span> value of <span class="keyword">yield</span>-<span class="keyword">from</span>: done</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"&lt;input&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">StopIteration</span><br></pre></td></tr></table></figure>
<p>当<code>caller</code>从<code>gen</code>被委派（yield from），<code>caller</code>就不再前进。注意到指令指针仍然停留在15，也就是<code>yield from</code>语句的位置，即使内部的生成器从一个yield语句运行到下一个，指针的位置仍然不变。从我们的角度看<code>caller</code>，不能区分它yield出的值是来自<code>caller</code>本身还是它委派的生成器。从<code>gen</code>往外看，我们不能区分它接收到的值是来自<code>caller</code>还是外面。<code>yield from</code>语句就像是一个光滑的管道，值通过这个管道从<code>gen</code>流入流出，直到<code>gen</code>结束。</p>
<p>一个协程可以使用<code>yield from</code>语句将任务委派给子协程，然后从中接收任务的结果。注意到上面的执行过程，<code>caller</code>打印了”return value of yield-from: done”。当<code>gen</code>执行完毕，它的返回值会变成<code>caller</code>中的<code>yield from</code>语句的返回值。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rv = <span class="keyword">yield</span> <span class="keyword">from</span> gen</span><br></pre></td></tr></table></figure>
<p>在上面，我们批判了基于回掉函数的异步编程时，最大的不满是关于“堆栈撕裂”：当一个回调抛出一个异常，它的堆栈回溯通常是没有用的。它仅仅显示了事件循环正在运行一个回调，而没有说明为什么。在这个问题上协程表现如何呢？</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">gen_fn</span><span class="params">()</span>:</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">raise</span> Exception(<span class="string">'my error'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>caller = caller_fn()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>caller.send(<span class="keyword">None</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"&lt;input&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">  File <span class="string">"&lt;input&gt;"</span>, line <span class="number">3</span>, <span class="keyword">in</span> caller_fn</span><br><span class="line">  File <span class="string">"&lt;input&gt;"</span>, line <span class="number">2</span>, <span class="keyword">in</span> gen_fn</span><br><span class="line">Exception: my error</span><br></pre></td></tr></table></figure>
<p>这样有用多了！堆栈回溯显示了发生错误的时候<code>caller_fn</code>正在委派给<code>gen_fn</code>。令人欣慰的是，你可以在一直异常处理器中封装这个调用给子协程，就像我们在正常的子程序中做的那样。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">gen_fn</span><span class="params">()</span>:</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">yield</span> <span class="number">1</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">raise</span> Exception(<span class="string">'uh oh'</span>)</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">caller_fn</span><span class="params">()</span>:</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">try</span>:</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">yield</span> <span class="keyword">from</span> gen_fn()</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">except</span> Exception <span class="keyword">as</span> exc:</span><br><span class="line"><span class="meta">... </span>        print(<span class="string">'caught &#123;&#125;'</span>.format(exc))</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>caller = caller_fn()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>caller.send(<span class="keyword">None</span>)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>caller.send(<span class="string">'hello'</span>)</span><br><span class="line">caught uh oh</span><br></pre></td></tr></table></figure>
<p>所以我们可以像常规子过程一样提取子协程。让我们从fetcher中提取一些有用的子协程。我们先写一个读取一块数据的子协程：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read</span><span class="params">(sock)</span>:</span></span><br><span class="line">    f = Future()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_readable</span><span class="params">()</span>:</span></span><br><span class="line">        f.set_result(sock.recv(<span class="number">4096</span>))</span><br><span class="line"></span><br><span class="line">    selector.register(sock.fileno(), EVENT_READ, on_readable)</span><br><span class="line">    chunk = <span class="keyword">yield</span> f  <span class="comment"># Read one chunk.</span></span><br><span class="line">    selector.unregister(sock.fileno())</span><br><span class="line">    <span class="keyword">return</span> chunk</span><br></pre></td></tr></table></figure>
<p>我们在<code>read</code>的基础上，构建<code>read_all</code>读取整个消息：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_all</span><span class="params">(sock)</span>:</span></span><br><span class="line">    response = []</span><br><span class="line">    <span class="comment"># Read whole response.</span></span><br><span class="line">    chunk = <span class="keyword">yield</span> <span class="keyword">from</span> read(sock)</span><br><span class="line">    <span class="keyword">while</span> chunk:</span><br><span class="line">        response.append(chunk)</span><br><span class="line">        chunk = <span class="keyword">yield</span> <span class="keyword">from</span> read(sock)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">b''</span>.join(response)</span><br></pre></td></tr></table></figure>
<p>如果你从另一个角度看，<code>yield from</code>语句消失了而且它就像一个普通阻塞I/O函数一样。但实际上，<code>read</code>和<code>read_all</code>函数都是协程。<code>read</code>通过<code>yield from</code>暂停<code>read_all</code>直到I/O操作完成。当<code>read_all</code>暂停的时候，异步I/O的事件循环会进行其它的任务并且等待其它I/O事件；<code>read</code>在下次循环中当事件就绪，完成I/O操作时，<code>read_all</code>恢复运行。</p>
<p>最后一步，<code>fetch</code>调用了<code>read_all</code>。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Fetcher</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fetch</span><span class="params">(self)</span>:</span></span><br><span class="line">         <span class="comment"># ... connection logic from above, then:</span></span><br><span class="line">        sock.send(request.encode(<span class="string">'ascii'</span>))</span><br><span class="line">        self.response = <span class="keyword">yield</span> <span class="keyword">from</span> read_all(sock)</span><br></pre></td></tr></table></figure>
<p>神奇的是，Task类不需要被修改，它可以像以前一样驱动<code>fetch</code>协程。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Task(fetcher.fetch())</span><br><span class="line">loop()</span><br></pre></td></tr></table></figure>
<p>当<code>read</code>yield出一个future，task从<code>yield from</code>管道接收它，就像这个future直接从<code>fetch</code>yield出来一样。当循环解决一个future，task向<code>fetch</code>发送它的结果，值被<code>read</code>接收，这个过程就像task直接驱动<code>read</code>一样。</p>
<p><img src="https://picbucket-1253466787.image.myqcloud.com/2018.2/Yield_From.png" alt="" title="图5.3 - Yield From"></p>
<p>为了完善我们的协程实现，我们再做一些打磨：我们的代码在等待一个future时使用<code>yield</code>，在委托一个子协程的时候使用<code>yield from</code>。如果我们不管是不是协程都使用<code>yield from</code>，代码将会更精炼。这样，协程不需要关心它等待的东西的类型。</p>
<p>我们在Python生成器和迭代器的高度相似性中得到好处。对于调用者来说，推进一个生成器就像推进一个迭代器一样。所以我们用一个特殊的方法实现来让Future类变成可迭代对象。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Method on Future class.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="comment"># Tell Task to resume me here.</span></span><br><span class="line">    <span class="keyword">yield</span> self</span><br><span class="line">    <span class="keyword">return</span> self.result</span><br></pre></td></tr></table></figure>
<p>future中的<code>__iter__</code>方法是一个yield它自身的协程。现在我们将我们的代码替换：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># f is a Future.</span></span><br><span class="line"><span class="keyword">yield</span> f</span><br></pre></td></tr></table></figure>
<p>替换成：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># f is a Future.</span></span><br><span class="line"><span class="keyword">yield</span> <span class="keyword">from</span> f</span><br></pre></td></tr></table></figure>
<p>结果是一样的！驱动Task从它调用的<code>send</code>中接收一个future，当future被解决时它向协程发送一个新的结果。</p>
<p>在所有地方都使用<code>yield from</code>的好处是什么？为什么比用<code>yield</code>等待future然后<code>yield from</code>委派子协程更好？原因是，一个方法可以快速地改变它的实现而不影响其调用者：它是一个普通的方法可以在future解决时返回一个值，或者是一个包含<code>yield from</code>语句并且会返回一个值的协程。另一方面，调用者只需要<code>yield from</code>这个方法然后等待结果就行了。</p>
<p>亲爱的读者，我们愉快地已经完成了对asynico中协程的愉快的阐述。我们专注于生成器的机制，并且简述了一个future类和task类的实现。我们指出了asynico如何利用了两个方面的优点：比线程更快和比回调函数更具有可读性的并发I/O。当然，真正的asynico会比我们的简化版本有着更精密。真正的框架需要处理零拷贝I/O，公平调度，异常处理，以及许多其它特性。</p>
<p>对于一个asynico用户来说，使用协程编程逼你在这里看到的版本要简便的多。在上面的代码中，我们从基本的原理去实现协程，所以你看到了回调函数，task类，future类。你也可以看到非阻塞sockets以及<code>select</code>的调用。但是当你使用asynico去构建一个应用程序时，这些都不会在你的代码中出现。就像我们承诺的那样，你可以轻松地抓取一个URL：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@asyncio.coroutine</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fetch</span><span class="params">(self, url)</span>:</span></span><br><span class="line">    response = <span class="keyword">yield</span> <span class="keyword">from</span> self.session.get(url)</span><br><span class="line">    body = <span class="keyword">yield</span> <span class="keyword">from</span> response.read()</span><br></pre></td></tr></table></figure>
<p>对我们的探索还满意吗，回到我们最原始的任务：使用asynico编写一个异步I/O的网页爬虫。</p>
<h1 id="使用协程工作"><a href="#使用协程工作" class="headerlink" title="使用协程工作"></a>使用协程工作</h1><p><strong>Coordinating Coroutines</strong></p>
<p>我们从描述我们想让爬虫进行什么工作开始。现在是时候开始用asynico协程实现它了。</p>
<p>我们的爬虫会抓取第一个页面，解析上面的链接，然后把它们添加到队列中。然后它开始遨游整个网站，并发的抓取网页。但是因为客户端以及服务器的负载限制，我们需要设置最大的worker数量，而不是越多越好。当一个worker完成一个页面的抓取，必须从队列中拉起另外一个链接。在某些时期，我们将会没有足够的工作去完成，此时一些worker必须可以暂停。同时，一但有一个worker抓取到一个页面上的大量新链接，队列里面的链接会突然增加，暂停的worker应该立刻被唤醒开始工作。最后，当任务完成，我们的程序会马上退出。</p>
<p>想象一下如果那些worker是线程。我们要如何表达爬虫的算法呢？我们可以使用Pyhton标准库中的同步队列。每当一个新的项目被加入队列，队列增加它的”tasks”计数。worker线程完成一个项目的工作后，调用<code>task_done</code>。主线程会在<code>Quene.join</code>阻塞，直到放入队列的任务数量与<code>task_done</code>的调用次数相等，然后退出。</p>
<p>协程使用一个asynico队列，使用跟线程几乎一样的模式来实现：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">from</span> asyncio <span class="keyword">import</span> JoinableQueue <span class="keyword">as</span> Queue</span><br><span class="line"><span class="keyword">except</span> ImportError:</span><br><span class="line">    <span class="comment"># In Python 3.5, asyncio.JoinableQueue is</span></span><br><span class="line">    <span class="comment"># merged into Queue.</span></span><br><span class="line">    <span class="keyword">from</span> asyncio <span class="keyword">import</span> Queue</span><br></pre></td></tr></table></figure>
<p>我们把worker的状态收集在一个crawler类中，然后在它的<code>crawl</code>方法中编写主逻辑。我们在一个协程中启动<code>crawl</code>并且运行asynico事件循环直到<code>crawl</code>完成</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line"></span><br><span class="line">crawler = crawling.Crawler(<span class="string">'http://xkcd.com'</span>,</span><br><span class="line">                           max_redirect=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">loop.run_until_complete(crawler.crawl())</span><br></pre></td></tr></table></figure>
<p>爬取器从一个根URL和<code>max_redirect</code>开始，<code>max_redirect</code>是最大重定向数。它把参数对<code>(URL, max_redirect)</code>放在队列中。（为什么要这样做呢，我们稍后再说）</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Crawler</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, root_url, max_redirect)</span>:</span></span><br><span class="line">        self.max_tasks = <span class="number">10</span></span><br><span class="line">        self.max_redirect = max_redirect</span><br><span class="line">        self.q = Queue()</span><br><span class="line">        self.seen_urls = set()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># aiohttp's ClientSession does connection pooling and</span></span><br><span class="line">        <span class="comment"># HTTP keep-alives for us.</span></span><br><span class="line">        self.session = aiohttp.ClientSession(loop=loop)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Put (URL, max_redirect) in the queue.</span></span><br><span class="line">        self.q.put((root_url, self.max_redirect))</span><br></pre></td></tr></table></figure>
<p>现在队列中未完成的任务数是1。回到我们的主程序，启动时间循环和<code>crawl</code>方法：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loop.run_until_complete(crawler.crawl())</span><br></pre></td></tr></table></figure>
<p><code>crawl</code>协程启动worker。它就像一个主线程一样：它在<code>join</code>阻塞直到所有的任务完成，此时，worker在后台工作。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@asyncio.coroutine</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crawl</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="string">"""Run the crawler until all work is done."""</span></span><br><span class="line">    workers = [asyncio.Task(self.work())</span><br><span class="line">               <span class="keyword">for</span> _ <span class="keyword">in</span> range(self.max_tasks)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># When all work is done, exit.</span></span><br><span class="line">    <span class="keyword">yield</span> <span class="keyword">from</span> self.q.join()</span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> workers:</span><br><span class="line">        w.cancel()</span><br></pre></td></tr></table></figure>
<p>如果worker是线程，我们不会希望一次性全部创建。为了在确切需要线程之前避免线程的昂贵开销，通常需要按需增长的线程池。但是协程的开销很小，所以我们可以直接把它们全部创建出来。</p>
<p>值得注意的是，我们如何关闭爬虫呢？当<code>join</code>future解决时，worker还是存活的，只是处于暂停状态：它们正在等待更多的URL但是已经没有了。所以，主协程在退出之前注销它们。否则，当Python解释器关闭以及调用所有对象的析构函数时，存活的worker会哭喊道：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ERROR:asyncio:Task was destroyed but it <span class="keyword">is</span> pending!</span><br></pre></td></tr></table></figure>
<p>那<code>cancel</code>又是如何工作的呢？生成器还有一个没有向你展示的特性。你可以从外面抛一个异常给它。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>gen = gen_fn()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>gen.send(<span class="keyword">None</span>)  <span class="comment"># Start the generator as usual.</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>gen.throw(Exception(<span class="string">'error'</span>))</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"&lt;input&gt;"</span>, line <span class="number">3</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">  File <span class="string">"&lt;input&gt;"</span>, line <span class="number">2</span>, <span class="keyword">in</span> gen_fn</span><br><span class="line">Exception: error</span><br></pre></td></tr></table></figure>
<p>生成器被<code>throw</code>重新启动，但是它现在抛出一个异常。如果生成器的调用堆栈里面没有可以捕获这个异常的代码，这个异常将会被传递到顶层。所以注销一个协程。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Method of Task class.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cancel</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.coro.throw(CancelledError)</span><br></pre></td></tr></table></figure>
<p>当生成器暂停时，它在某一个<code>yield from</code>语句处恢复然后抛出一个异常。我们在task的<code>step</code>方法中处理注销：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Method of Task class.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">step</span><span class="params">(self, future)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        next_future = self.coro.send(future.result)</span><br><span class="line">    <span class="keyword">except</span> CancelledError:</span><br><span class="line">        self.cancelled = <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    next_future.add_done_callback(self.step)</span><br></pre></td></tr></table></figure>
<p>现在task知道协程被注销了，所以当它被销毁时，它将不会再抱怨。</p>
<p>一旦<code>crawl</code>注销了worker，它就会退出。事件循环看到这个协程结束了（我们会在晚一些看到），同样也会结束：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loop.run_until_complete(crawler.crawl())</span><br></pre></td></tr></table></figure>
<p><code>crawl</code>方法包含了所以我们主协程需要做的事情。而worker协程则是负责从队列中取出URL，抓取它们的页面，然后解析它们获得新的链接。每一个worker独立地运行一个<code>work</code>协程：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@asyncio.coroutine</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">work</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        url, max_redirect = <span class="keyword">yield</span> <span class="keyword">from</span> self.q.get()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Download page and add new links to self.q.</span></span><br><span class="line">        <span class="keyword">yield</span> <span class="keyword">from</span> self.fetch(url, max_redirect)</span><br><span class="line">        self.q.task_done()</span><br></pre></td></tr></table></figure>
<p>Python看到代码中包含<code>yield from</code>语句，然后把代码解释成生成器函数。所以在<code>crawl</code>中，当主协程调用了10次<code>self.work</code>时，它并没有实际运行这个方法：只是创建了10个指向这些代码的生成器对象。它们被包装成Task对象。Task接收每一个从生成器yield出的future，然后通过调用<code>send</code>方法，用future解决时的结果作为参数，来驱动生成器。因为生成器有自己的栈帧，它们会独立地运行，有着独立的局部变量和指令指针。</p>
<p>worker通过队列与同伴协调。它这样等待新的URL：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">url, max_redirect = <span class="keyword">yield</span> <span class="keyword">from</span> self.q.get()</span><br></pre></td></tr></table></figure>
<p>队列的<code>get</code>方法本来就是一个协程：它等待有人向队列加入一个新的条目，然后恢复返回那个条目。</p>
<p>碰巧，这也是当主协程注销worker时，最后crawl停止，worker协程暂停的地方。从协程的角度，<code>yield from</code>抛出<code>CancelledError</code>结束了它在循环中的最后旅程。</p>
<p>当worker爬取了一个页面时，他解析上面的链接，把新的链接放到队列中，然后调用<code>task_done</code>来减小计数器。最终，一个worker抓取了一个没有新链接的页面，而且队列中也没有新的任务。这时worker对<code>task_done</code>的调用使计数器减为零。而<code>crawl</code>正阻塞在队列的<code>join</code>方法上，现在它可以结束了。</p>
<p>我们说过要解释为什么队列中的元素是成对的：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># URL to fetch, and the number of redirects left.</span></span><br><span class="line">(<span class="string">'http://xkcd.com/353'</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p>新的URL的重定向次数是10。爬取这些特殊的URL会重定向到一个带末位斜杠的新位置。我们减少重定向的次数，然后把下一个新的位置放进队列：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># URL with a trailing slash. Nine redirects left.</span></span><br><span class="line">(<span class="string">'http://xkcd.com/353/'</span>, <span class="number">9</span>)</span><br></pre></td></tr></table></figure>
<p>我们使用的<code>aiohttp</code>库会默认跟踪重定向并且向我们返回最终的结果。但是，我们现在要告诉它不要这样做，我们在爬虫中处理重定向，以便它可以合并那些相同的重定向路径：如果我们已经在<code>self.seen_urls</code>中看到这个URL，说明它已经从其它的入口走过这条路了：</p>
<p><img src="https://picbucket-1253466787.image.myqcloud.com/2018.2/redirects.png" alt="" title="图5.4 - 重定向"></p>
<p>爬虫抓取了”foo”并发现它重定向到”baz”，所以它把”baz”加入到队列中和<code>seen_urls</code>中。如果它抓取的下一个页面是”bar”，这个页面也重定向到”baz”，爬虫就不会在把它加入到队列中。如果它的响应是一个页面而不是重定向，<code>fetch</code>会解析这个页面并且把新的连接加入队列中。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@asyncio.coroutine</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fetch</span><span class="params">(self, url, max_redirect)</span>:</span></span><br><span class="line">    <span class="comment"># Handle redirects ourselves.</span></span><br><span class="line">    response = <span class="keyword">yield</span> <span class="keyword">from</span> self.session.get(</span><br><span class="line">        url, allow_redirects=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> is_redirect(response):</span><br><span class="line">            <span class="keyword">if</span> max_redirect &gt; <span class="number">0</span>:</span><br><span class="line">                next_url = response.headers[<span class="string">'location'</span>]</span><br><span class="line">                <span class="keyword">if</span> next_url <span class="keyword">in</span> self.seen_urls:</span><br><span class="line">                    <span class="comment"># We have been down this path before.</span></span><br><span class="line">                    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># Remember we have seen this URL.</span></span><br><span class="line">                self.seen_urls.add(next_url)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Follow the redirect. One less redirect remains.</span></span><br><span class="line">                self.q.put_nowait((next_url, max_redirect - <span class="number">1</span>))</span><br><span class="line">         <span class="keyword">else</span>:</span><br><span class="line">             links = <span class="keyword">yield</span> <span class="keyword">from</span> self.parse_links(response)</span><br><span class="line">             <span class="comment"># Python set-logic:</span></span><br><span class="line">             <span class="keyword">for</span> link <span class="keyword">in</span> links.difference(self.seen_urls):</span><br><span class="line">                self.q.put_nowait((link, self.max_redirect))</span><br><span class="line">            self.seen_urls.update(links)</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        <span class="comment"># Return connection to pool.</span></span><br><span class="line">        <span class="keyword">yield</span> <span class="keyword">from</span> response.release()</span><br></pre></td></tr></table></figure>
<p>如果这是一些多线程代码，它会遇到讨厌的竞态条件。比如说，worker检查一个URL是否在<code>seen_urls</code>中，如果没有，worker就会把它加入到队列中并且加入到<code>seen_urls</code>中。如果它在这两个步骤之间中断，然后另一个worker从另一个页面解析到同样的链接，它并没有在<code>seen_urls</code>，所以把它加入到队列中。现在同样的链接在队列中至少出现了两次，导致了重复的工作和错误的统计。</p>
<p>然而，一个协程只有在<code>yield from</code>语句时才会被中断。这是协程比多线程程序少遇到竞争的关键：多线程必须明确的有锁地进入临界区，否则它可能是中断的。一个Python协程默认是不可以中断的，并且只会在它明确yield时才会交出控制权。</p>
<p>我们不再需要一个像我们的回调函数编程中的fetcher类了。这个类是一个有缺陷的回调的变通方法：它们需要一些位置来存储等待I/O时的状态，因为它们的局部变量不能在调用之间保留。但是<code>fetch</code>协程可以像普通函数在一样局部变量中存储它的状态，所以它不再需要一个类。</p>
<p>当<code>fetch</code>完成处理服务器响应的工作时，它返回到它的调用者<code>worke</code>。<code>work</code>对队列调用<code>task_done</code>然后从队列取出要爬取的下一个URL。</p>
<p>当<code>fetch</code>把新的链接放入队列中时，它增加未完成任务的计数器并且停留在主协程中，主协程在等待<code>q.join</code>，处于暂停状态。而当页面中没有新的链接并且这是队列中最后一个URL时，<code>work</code>调用<code>task_done</code>，任务计数器减少到0。然后主协程从<code>join</code>中退出。</p>
<p>协调worker和主协程的队列代码像这样：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Queue</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self._join_future = Future()</span><br><span class="line">        self._unfinished_tasks = <span class="number">0</span></span><br><span class="line">        <span class="comment"># ... other initialization ...</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">put_nowait</span><span class="params">(self, item)</span>:</span></span><br><span class="line">        self._unfinished_tasks += <span class="number">1</span></span><br><span class="line">        <span class="comment"># ... store the item ...</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">task_done</span><span class="params">(self)</span>:</span></span><br><span class="line">        self._unfinished_tasks -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> self._unfinished_tasks == <span class="number">0</span>:</span><br><span class="line">            self._join_future.set_result(<span class="keyword">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @asyncio.coroutine</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">join</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self._unfinished_tasks &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">yield</span> <span class="keyword">from</span> self._join_future</span><br></pre></td></tr></table></figure>
<p>主协程<code>crawl</code>yield from<code>join</code>，所以当最后的worker把计数器减为0，它告诉<code>crawl</code>恢复运行，然后结束。</p>
<p>旅程快要结束了。我们的程序从调用<code>crawl</code>开始：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loop.run_until_complete(self.crawler.crawl())</span><br></pre></td></tr></table></figure>
<p>程序如何结束？因为<code>crawl</code>是一个生成器函数，调用它会返回一个生成器。为了驱动它，asynico把它包装在一个task里：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EventLoop</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run_until_complete</span><span class="params">(self, coro)</span>:</span></span><br><span class="line">        <span class="string">"""Run until the coroutine is done."""</span></span><br><span class="line">        task = Task(coro)</span><br><span class="line">        task.add_done_callback(stop_callback)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.run_forever()</span><br><span class="line">        <span class="keyword">except</span> StopError:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StopError</span><span class="params">(BaseException)</span>:</span></span><br><span class="line">    <span class="string">"""Raised to stop the event loop."""</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stop_callback</span><span class="params">(future)</span>:</span></span><br><span class="line">    <span class="keyword">raise</span> StopError</span><br></pre></td></tr></table></figure>
<p>当task完成的时候，它抛出<code>StopError</code>异常，事件循环把这个异常作为正常退出的信号。</p>
<p>但task的<code>add_done_callback</code>和<code>result</code>方法又是什么呢？你可能想到一个task就像一个future。你的直觉是对的。我们必须承认一个我们像你隐藏的关于Task类的细节：一个task是一个future。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Task</span><span class="params">(Future)</span>:</span></span><br><span class="line">    <span class="string">"""A coroutine wrapped in a Future."""</span></span><br></pre></td></tr></table></figure>
<p>通常情况下，future通过别人调用它的<code>set_result</code>来解决。但是一个task会在写协程停止的时候解决它自身。还记得我们之前关于Python协程探索，当一个生成器返回时，它会抛出一个特殊的异常<code>StopIteration</code>：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Method of class Task.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">step</span><span class="params">(self, future)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        next_future = self.coro.send(future.result)</span><br><span class="line">    <span class="keyword">except</span> CancelledError:</span><br><span class="line">        self.cancelled = <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">except</span> StopIteration <span class="keyword">as</span> exc:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Task resolves itself with coro's return</span></span><br><span class="line">        <span class="comment"># value.</span></span><br><span class="line">        self.set_result(exc.value)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    next_future.add_done_callback(self.step)</span><br></pre></td></tr></table></figure>
<p>所以当事件循环调用<code>task.add_done_callback(stop_callback)</code>，他就准备被这个task停止。再看一次<code>run_until_complete</code>：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Method of event loop.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_until_complete</span><span class="params">(self, coro)</span>:</span></span><br><span class="line">    task = Task(coro)</span><br><span class="line">    task.add_done_callback(stop_callback)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        self.run_forever()</span><br><span class="line">    <span class="keyword">except</span> StopError:</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>当task捕获<code>StopIteration</code>然后解决它自身，回调从循环中抛出<code>StopError</code>。事件循环结束，调用堆栈回到<code>run_until_complete</code>。我们的程序完成了。</p>
<h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p><strong>Conclusion</strong></p>
<p>现代程序更多的是I/O密集型而不是CPU密集型。对于这些程序，Python多线程有两个缺陷：GIL全局锁使得它们实际上并没有进行并行计算，抢占式切换是的他们更容易出现竞争。异步I/O通常上来说是正确的模式。但是随着基于回调函数的代码的增加，会导致出现混乱难以读懂的程序。协程是一个简洁的替代者。它们可以自然地被分解成子过程，有着完整的异常处理和堆栈跟踪。</p>
<p>如果我们从另一个角度看<code>yield from</code>语句，一个协程更像一个传统的做阻塞I/O的线程。我们可以使用与传统多线程编程相似的模式进行协程的编程，它不需要被重塑。因此，相比于回调函数，协程对于有着丰富检验的多线程程序员更为适合。</p>
<p>但是当我们关注<code>yield from</code>语句的时候，我们可以看到协程放弃控制权，允许其它人运行的特点。不像线程那样，协程可以显示代码中可以中断的地方和不可以中断的地方。Glyph Lefkowitz富有启发性的文章写道：“线程让局部推理变得困难，而局部推理也许是软件开发中最重要的事情。”然而明确的yield，让“通过过程本身而不是整个系统去理解它的行为（和因此、正确性）”成为可能。</p>
<p>这一篇文章写于Python和异步的复兴时期。你刚刚学到的基于生成器的协程，包含在2014年3月发布的Python 3.4 的”asynico”库中。在2015年9月，Python 3.5发布，协程成为语言的一部分。这个原生的协程通过新的语法”async def”来声明，使用新的”await”关键字代替”yield from”委派协程或者等待一个Future。</p>
<p>尽管有了这些改进，核心思想还是不变的。Python的新原生协程与生成器语法不同，但是它们的工作原理非常相似；实际上，它们在Python解释器中共用一种实现方法。Task，Future，以及事件循环在asynico中还是扮演着同样的角色。</p>
<p>现在你知道了asynico协程是如何工作的，你可以忘记大部分的细节。它们的机制隐藏在一个整洁的接口下。但是理解这些基本原理可以让在现代异步环境中你高效而正确地编写代码。</p>

      
    </div>
    
    
    

    
      <div>
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束 <i class="fa fa-lemon-o"></i> 感谢阅读-------------</div>
    
</div>
      </div>
    

    
      <div>
        
      </div>
    

    



    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/爬虫/" rel="tag"># 爬虫</a>
          
            <a href="/tags/Python/" rel="tag"># Python</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/A-Web-Crawler-With-asyncio-Coroutines-Part-1.html/" rel="next" title="翻译 | 500 Lines or Less 基于Python协程的网页爬虫 （一）">
                <i class="fa fa-chevron-left"></i> 翻译 | 500 Lines or Less 基于Python协程的网页爬虫 （一）
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/PAT-A-1016-Phone-Bills.html/" rel="prev" title="PAT-A 1016. Phone Bills">
                PAT-A 1016. Phone Bills <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/sheep.jpg"
                alt="YANG Yi" />
            
              <p class="site-author-name" itemprop="name">YANG Yi</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/yangyiLTS" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:yeyonglts@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#用生成器构建协程"><span class="nav-number">1.</span> <span class="nav-text">用生成器构建协程</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#用yield-from重构协程"><span class="nav-number">2.</span> <span class="nav-text">用yield from重构协程</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#使用协程工作"><span class="nav-number">3.</span> <span class="nav-text">使用协程工作</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#结论"><span class="nav-number">4.</span> <span class="nav-text">结论</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">YANG Yi</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">23.0k</span>
  
</div>

<div class="powered-by"><a class="mii-link" target="_blank" href="http://www.miitbeian.gov.cn/">粤ICP备18001530号-1</a></div>
<span class="post-meta-divider">|</span>

  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://yangyilts.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'https://www.yangyilts.com/2018/A-Web-Crawler-With-asyncio-Coroutines-Part-2.html/';
          this.page.identifier = '2018/A-Web-Crawler-With-asyncio-Coroutines-Part-2.html/';
          this.page.title = '翻译 | 500 Lines or Less 基于Python协程的网页爬虫 （二）';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://yangyilts.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  





  

  

  

  
  

  

  

  

</body>
</html>
